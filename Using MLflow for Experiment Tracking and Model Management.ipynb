{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4d4ded",
   "metadata": {},
   "source": [
    "### Using MLflow for Experiment Tracking and Model Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab0c67",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "The objective of this task is to introduce you to MLflow for experiment tracking, model management, and reproducibility in machine learning projects for the Sentiment Analysis Project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7de27",
   "metadata": {},
   "source": [
    "#### To integrate MLflow into your machine learning project and demonstrate experiment tracking, model management, and reproducibility, let's follow these steps:\n",
    "\n",
    "1.\tIntegrate MLflow into your existing machine learning projects.\n",
    "2.\tTrain machine learning models while logging relevant information with MLflow.\n",
    "3.\tDemonstrate how to log parameters, metrics, and artifacts using MLflow tracking APIs.\n",
    "4.\tCustomizing MLflow UI with run names.\n",
    "5.\tDemonstrate metric plots.\n",
    "6.\tDemonstrate hyperparameter plots.\n",
    "7.\tDemonstrate how to register models and manage by tagging them.\n",
    "8.\t(BONUS) Build a Prefect Workflow and Auto Schedule it. Show the Prefect Dashboard with relevant outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cac3e",
   "metadata": {},
   "source": [
    "#### Load Data from the Dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0dee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Dataset/data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d8430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8518 entries, 0 to 8517\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8518 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# print properties of attributes in the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001d72cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of null values per column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4413549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784b7aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name      0\n",
       "Review Title       0\n",
       "Place of Review    0\n",
       "Up Votes           0\n",
       "Down Votes         0\n",
       "Month              0\n",
       "Review text        0\n",
       "Ratings            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4019b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8013 entries, 0 to 8507\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8013 non-null   object \n",
      " 1   Review Title     8013 non-null   object \n",
      " 2   Place of Review  8013 non-null   object \n",
      " 3   Up Votes         8013 non-null   float64\n",
      " 4   Down Votes       8013 non-null   float64\n",
      " 5   Month            8013 non-null   object \n",
      " 6   Review text      8013 non-null   object \n",
      " 7   Ratings          8013 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 563.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b32fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a sentiment column to classify reviews as Positive or Negative\n",
    "# Positive = 1\n",
    "# Negative = 0\n",
    "\n",
    "# Method 1: Using numpy's where function\n",
    "data['sentiment'] = np.where(data['Ratings'] == 5.0, 1,\n",
    "                              np.where(data['Ratings'] == 4.0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba86dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using pandas' map function\n",
    "# Create a dictionary mapping star ratings to sentiments\n",
    "rating_sentiment_map = {5.0: 1, 4.0: 1, 1.0: 0, 2.0: 0, 3.0: 0}\n",
    "\n",
    "# Map star ratings to sentiments using the dictionary\n",
    "data['sentiment'] = data['Ratings'].map(rating_sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e85d3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baji Sankar</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>173.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Oct 2018</td>\n",
       "      <td>Good quality product. Delivered on time.READ MORE</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Certified Buyer, Doom Dooma</td>\n",
       "      <td>403.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Jan 2020</td>\n",
       "      <td>BEST PURCHASE It is a good quality and is more...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "5             Baji Sankar      Mind-blowing purchase   \n",
       "6       Flipkart Customer                  Must buy!   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "5   Certified Buyer, Hyderabad     173.0        45.0  Oct 2018   \n",
       "6  Certified Buyer, Doom Dooma     403.0       121.0  Jan 2020   \n",
       "\n",
       "                                         Review text  Ratings  sentiment  \n",
       "0  Nice product, good quality, but price is now r...        4          1  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1          0  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1          0  \n",
       "5  Good quality product. Delivered on time.READ MORE        5          1  \n",
       "6  BEST PURCHASE It is a good quality and is more...        5          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c9649",
   "metadata": {},
   "source": [
    "#### Identify input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d460560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Review text\"]\n",
    "y = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbb0b6",
   "metadata": {},
   "source": [
    "#### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b4d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0568243-7f3f-4bef-bb35-7ab7064e70e6",
   "metadata": {},
   "source": [
    "#### Data Cleaning and preprocessing on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12f19d5-d95c-45eb-8ded-04ca638e0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Preprocessing functions\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb7814b4-2245-47d0-9cad-8969d6ac17bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6009,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply text cleaning to the X_train data\n",
    "X_train = X_train.apply(clean_text)\n",
    "X_train = X_train.apply(lemmatize_text)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb973798-c447-4cb6-826f-85ada123ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply text cleaning to the X_test data\n",
    "X_test = X_test.apply(clean_text)\n",
    "X_test = X_test.apply(lemmatize_text)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b29f7",
   "metadata": {},
   "source": [
    "#### Running the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbb0c90-6175-47d0-9764-18d462bd5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b3902f-5522-44de-b952-62129638090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 23:29:58 INFO mlflow.tracking.fluent: Experiment with name 'Sentiment Analysis of Flipkart Product Reviews' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///E:/Innomatic%20Research%20Lab%20%28Internship%20Data%20Scientists%29/Project/Using%20MLflow%20for%20Experiment%20Tracking%20and%20Model%20Management%20%28Sentiment%20Analysis%20Project%29/mlruns/621815518864309614', creation_time=1711475998558, experiment_id='621815518864309614', last_update_time=1711475998558, lifecycle_stage='active', name='Sentiment Analysis of Flipkart Product Reviews', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# mlflow.set_tracking_uri(\"sqlite:///mlflow_1.db\")\n",
    "\n",
    "mlflow.set_experiment(\"Sentiment Analysis of Flipkart Product Reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf6300-6f76-4b9d-ab29-be572e02fce5",
   "metadata": {},
   "source": [
    "#### Auto Logging All Experiment Runs using MLFlow\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17dc1fb1-c29f-4304-adc5-2750fd7f2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines for various classifiers\n",
    "pipelines = {\n",
    "    'knn': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'svc': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'random_forest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'knn': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__n_neighbors': [3, 5, 7],\n",
    "            'classifier__p': [1, 2, 3]\n",
    "        }\n",
    "    ],\n",
    "    'svc': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel': ['rbf'],\n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "        },\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__kernel': ['linear'],\n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__penalty': ['l1', 'l2']\n",
    "        }\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 2000, 3000],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b2e6e1-2bf2-4c18-b587-fb0393bcf765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** knn **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 23:29:59 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 1min 50s\n",
      "Wall time: 39.6 s\n",
      "Score on Test Data:  0.8637724550898204\n",
      "********** svc **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 23:30:39 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 1min 4s\n",
      "Wall time: 1min 40s\n",
      "Score on Test Data:  0.8822355289421158\n",
      "********** logistic_regression **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 23:32:19 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 23:32:31 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.08 s\n",
      "Wall time: 11.7 s\n",
      "Score on Test Data:  0.8802395209580839\n",
      "********** random_forest **********\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "CPU times: total: 1min 31s\n",
      "Wall time: 2min 19s\n",
      "Score on Test Data:  0.8822355289421158\n",
      "********** decision_tree **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/26 23:34:51 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "CPU times: total: 5.61 s\n",
      "Wall time: 13.6 s\n",
      "Score on Test Data:  0.8667664670658682\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for each algorithm\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "        \n",
    "    # print('Score on Train Data: ', grid_search.best_score_)\n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26503c78-e9c9-4c3d-bff5-ca9cddaa17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the auto logger\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a952345-a842-4622-9036-9c8eeaabc1dd",
   "metadata": {},
   "source": [
    "#### Custom Experiment Tracking and Database Integration with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb062644-2acd-44b5-a855-93cf8b64b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** knn **********\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Train Score:  0.8597113331790895\n",
      "Test Score:  0.8637724550898204\n",
      "Fit Time:  27.944451570510864\n",
      "Predict Time:  0.10474681854248047\n",
      "Model Size:  425387\n",
      "\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Train Score:  0.878681935879834\n",
      "Test Score:  0.8822355289421158\n",
      "Fit Time:  90.88646078109741\n",
      "Predict Time:  0.13266491889953613\n",
      "Model Size:  287485\n",
      "\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Train Score:  0.8733573381028844\n",
      "Test Score:  0.8802395209580839\n",
      "Fit Time:  4.99422025680542\n",
      "Predict Time:  0.008019685745239258\n",
      "Model Size:  120929\n",
      "\n",
      "********** random_forest **********\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Train Score:  0.8741891463159513\n",
      "Test Score:  0.8812375249500998\n",
      "Fit Time:  137.07349634170532\n",
      "Predict Time:  0.16272974014282227\n",
      "Model Size:  29657282\n",
      "\n",
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Train Score:  0.858212305053609\n",
      "Test Score:  0.8687624750499002\n",
      "Fit Time:  8.053020715713501\n",
      "Predict Time:  0.008036136627197266\n",
      "Model Size:  71200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev = \"Angad Gupta\"\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "\n",
    "    # Fit\n",
    "    start_fit_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_fit_time = time.time()\n",
    "\n",
    "    # Predict\n",
    "    start_predict_time = time.time()\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    end_predict_time = time.time()\n",
    "\n",
    "    # Saving the best model\n",
    "    model_path = f'Best Models/{algo}.pkl'\n",
    "    joblib.dump(grid_search.best_estimator_, model_path)\n",
    "    model_size = os.path.getsize(model_path)\n",
    "\n",
    "    # Pring Log\n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "    print(\"Fit Time: \", end_fit_time - start_fit_time)\n",
    "    print(\"Predict Time: \", end_predict_time - start_predict_time)\n",
    "    print(\"Model Size: \", model_size)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    # Start the experiment run\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log tags with mlflow.set_tag()\n",
    "        mlflow.set_tag(\"developer\", dev)\n",
    "\n",
    "        # Log Parameters with mlflow.log_param()\n",
    "        mlflow.log_param(\"algorithm\", algo)\n",
    "        mlflow.log_param(\"hyperparameter_grid\", param_grids[algo])\n",
    "        mlflow.log_param(\"best_hyperparameter\", grid_search.best_params_)\n",
    "\n",
    "        # Log Metrics with mlflow.log_metric()\n",
    "        mlflow.log_metric(\"train_score\", grid_search.best_score_)\n",
    "        mlflow.log_metric(\"test_score\", grid_search.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"fit_time\", end_fit_time - start_fit_time)\n",
    "        mlflow.log_metric(\"predict_time\", end_predict_time - start_predict_time)\n",
    "        mlflow.log_metric(\"model_size\", model_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320baf9-613d-488e-b2fc-9980f6467295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
